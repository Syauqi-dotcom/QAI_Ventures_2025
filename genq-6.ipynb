{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccd880",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import gdown\n",
    "\n",
    "# url = 'https://drive.google.com/uc?id=1tHg-m1L3Du2YRCq1hqXT1A2pWAp3qYKZ'\n",
    "# output = 'easy.csv'\n",
    "# gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585d705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\i'\n",
      "/tmp/ipykernel_2195670/3651953690.py:21: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# pip install qiskit numpy scikit-learn\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, SparsePauliOp\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Feature map (IQP-style)\n",
    "# -----------------------------\n",
    "def iqp_feature_map(x: np.ndarray, gamma: float = 1.0) -> QuantumCircuit:\n",
    "    \"\"\"\n",
    "    IQP-style data-embedding circuit for a single sample x \\in R^n.\n",
    "    - Hadamards\n",
    "    - Single-qubit RZ rotations with angle gamma * x_j\n",
    "    - Two-qubit ZZ rotations with angle gamma * x_j * x_k\n",
    "    (Pairs-only IQP; captures up to quadratic interactions as in common IQP maps.)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x).ravel()\n",
    "    n = len(x)\n",
    "    qc = QuantumCircuit(n)\n",
    "    # H layer\n",
    "    for q in range(n): qc.h(q)\n",
    "    # Single qubit Z rotations\n",
    "    for j in range(n): qc.rz(gamma * float(x[j]), j)\n",
    "    # Pairwise ZZ (RZZ) rotations\n",
    "    for j in range(n):\n",
    "        for k in range(j+1, n):\n",
    "            angle = gamma * float(x[j]) * float(x[k])\n",
    "            if abs(angle) > 0:\n",
    "                qc.rzz(angle, j, k)\n",
    "    # Optional final H layer (often omitted in IQP feature maps); keep simple\n",
    "    return qc\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Enumerate H-body Pauli strings\n",
    "# -----------------------------\n",
    "def generate_h_body_paulis(n_qubits: int, H: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns all length-n Pauli strings with exactly H non-identity factors,\n",
    "    each chosen from {'X','Y','Z'}. (e.g., 'IXYZI' for n=5, H=3)\n",
    "    \"\"\"\n",
    "    if H == 0:\n",
    "        return ['I' * n_qubits]\n",
    "    paulis = []\n",
    "    for subset in itertools.combinations(range(n_qubits), H):\n",
    "        for letters in itertools.product('XYZ', repeat=H):\n",
    "            s = ['I'] * n_qubits\n",
    "            for idx, letter in zip(subset, letters):\n",
    "                s[idx] = letter\n",
    "            paulis.append(''.join(s))\n",
    "    return paulis\n",
    "\n",
    "def sample_paulis(paulis_all: List[str], p: Optional[int], seed: int) -> List[str]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if p is None or p >= len(paulis_all):\n",
    "        return paulis_all\n",
    "    idx = rng.choice(len(paulis_all), size=p, replace=False)\n",
    "    return [paulis_all[i] for i in idx]\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Expectation values ⟨P⟩_x for a state\n",
    "# -----------------------------\n",
    "def statevector_from_feature_map(x: np.ndarray, gamma: float, feature_map_fn) -> Statevector:\n",
    "    qc = feature_map_fn(x, gamma=gamma)\n",
    "    psi = Statevector.from_label('0' * qc.num_qubits).evolve(qc)\n",
    "    return psi\n",
    "\n",
    "def expectation_pauli(psi: Statevector, pauli_str: str) -> float:\n",
    "    op = SparsePauliOp.from_list([(pauli_str, 1.0)])\n",
    "    val = psi.expectation_value(op)\n",
    "    return float(np.real_if_close(val))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) H-body LPQK feature matrix Φ (N x p)\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class HBodyLPQK:\n",
    "    H: int = 2\n",
    "    p: Optional[int] = None            # number of Lego features; if None use full d_H\n",
    "    gamma: float = 1.0                 # kernel bandwidth (scales embedding)\n",
    "    seed: int = 0\n",
    "    feature_map_fn: callable = iqp_feature_map\n",
    "\n",
    "    # will be set after fit_features(...)\n",
    "    pauli_basis_: Optional[List[str]] = None\n",
    "\n",
    "    def fit_features(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute and cache the Pauli subset; return Φ_train.\n",
    "        \"\"\"\n",
    "        n_qubits = X.shape[1]\n",
    "        all_paulis = generate_h_body_paulis(n_qubits, self.H)\n",
    "        self.pauli_basis_ = sample_paulis(all_paulis, self.p, self.seed)\n",
    "        return self.transform_features(X)\n",
    "\n",
    "    def transform_features(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute Φ(X): each row i is [⟨P_1⟩_{x_i},...,⟨P_p⟩_{x_i}] / sqrt(p or d_H).\n",
    "        \"\"\"\n",
    "        assert self.pauli_basis_ is not None, \"Call fit_features on training data first.\"\n",
    "        norm = math.sqrt(len(self.pauli_basis_))\n",
    "        Φ = np.empty((len(X), len(self.pauli_basis_)), dtype=float)\n",
    "        # Cache states to avoid re-simulation\n",
    "        states = [statevector_from_feature_map(x, self.gamma, self.feature_map_fn) for x in X]\n",
    "        for i, psi in enumerate(states):\n",
    "            Φ[i, :] = [expectation_pauli(psi, P) for P in self.pauli_basis_]\n",
    "        return Φ / norm\n",
    "\n",
    "    def kernel_train(self, X: np.ndarray) -> np.ndarray:\n",
    "        Φ = self.fit_features(X)\n",
    "        return Φ @ Φ.T\n",
    "\n",
    "    def kernel_test(self, X_test: np.ndarray, X_train: np.ndarray) -> np.ndarray:\n",
    "        # make sure the same pauli_basis_ is used as in training\n",
    "        Φ_train = self.transform_features(X_train)  # cheap: reuse states if you cache externally\n",
    "        Φ_test  = self.transform_features(X_test)\n",
    "        return Φ_test @ Φ_train.T\n",
    "\n",
    "# -----------------------------\n",
    "# 5) GFQK (fidelity) kernel\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class GFQK:\n",
    "    gamma: float = 1.0\n",
    "    feature_map_fn: callable = iqp_feature_map\n",
    "\n",
    "    def _states(self, X: np.ndarray) -> List[Statevector]:\n",
    "        return [statevector_from_feature_map(x, self.gamma, self.feature_map_fn) for x in X]\n",
    "\n",
    "    def kernel_train(self, X: np.ndarray) -> np.ndarray:\n",
    "        states = self._states(X)\n",
    "        N = len(states)\n",
    "        K = np.empty((N, N), dtype=float)\n",
    "        for i in range(N):\n",
    "            for j in range(i, N):\n",
    "                fid = abs(states[i].data.conj().dot(states[j].data))**2\n",
    "                K[i, j] = K[j, i] = float(np.real_if_close(fid))\n",
    "        return K\n",
    "\n",
    "    def kernel_test(self, X_test: np.ndarray, X_train: np.ndarray) -> np.ndarray:\n",
    "        S_test  = self._states(X_test)\n",
    "        S_train = self._states(X_train)\n",
    "        K = np.empty((len(X_test), len(X_train)), dtype=float)\n",
    "        for i, psi in enumerate(S_test):\n",
    "            for j, phi in enumerate(S_train):\n",
    "                fid = abs(psi.data.conj().dot(phi.data))**2\n",
    "                K[i, j] = float(np.real_if_close(fid))\n",
    "        return K\n",
    "\n",
    "# -----------------------------\n",
    "# 6) SVM wrapper (precomputed kernel)\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class QuantumKernelSVC:\n",
    "    kernel: object\n",
    "    C: float = 1.0\n",
    "    scale_X: bool = True\n",
    "\n",
    "    # learned artifacts\n",
    "    svc_: Optional[SVC] = None\n",
    "    scaler_: Optional[StandardScaler] = None\n",
    "    X_train_: Optional[np.ndarray] = None\n",
    "    y_train_: Optional[np.ndarray] = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y)\n",
    "        if self.scale_X:\n",
    "            self.scaler_ = StandardScaler().fit(X)\n",
    "            Xs = self.scaler_.transform(X)\n",
    "        else:\n",
    "            Xs = X\n",
    "\n",
    "        K_train = self.kernel.kernel_train(Xs)\n",
    "\n",
    "        self.svc_ = SVC(C=self.C, kernel='precomputed').fit(K_train, y)\n",
    "        self.X_train_ = Xs\n",
    "        self.y_train_ = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        assert self.svc_ is not None and self.X_train_ is not None\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        Xs = self.scaler_.transform(X) if (self.scaler_ is not None) else X\n",
    "        K_test = self.kernel.kernel_test(Xs, self.X_train_)\n",
    "        return self.svc_.predict(K_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Example usage\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Dummy binary dataset (replace with your own)\n",
    "    # rng = np.random.default_rng(0)\n",
    "    # N_train, N_test, n_features = 100, 20, 8\n",
    "    # X_train = rng.normal(size=(N_train, n_features))\n",
    "    # y_train = (X_train[:, 0] + 0.5 * X_train[:, 1] > 0).astype(int)\n",
    "    # X_test  = rng.normal(size=(N_test,  n_features))\n",
    "    data = pd.read_csv(\"easy.csv\")\n",
    "    print(data.head())\n",
    "    \n",
    "    num_rows = int(len(data) * 0.80)\n",
    "    \n",
    "    data_train = data[:num_rows]\n",
    "    data_test = data[num_rows:]\n",
    "    \n",
    "    X_train = data_train.drop(columns=[\"Class\"]).to_numpy()\n",
    "    y_train = data_train[\"Class\"].to_numpy()\n",
    "    X_test = data_test.drop(columns=[\"Class\"]).to_numpy()\n",
    "    y_test = data_test[\"Class\"].to_numpy()\n",
    "    \n",
    "\n",
    "    # H-body LPQK (H=2), use p=150 Lego features, bandwidth gamma=0.5\n",
    "    kernel = HBodyLPQK(H=2, p=150, gamma=0.5, seed=42)\n",
    "    clf = QuantumKernelSVC(kernel=kernel, C=2.0).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"LPQK(H=2,p=150) preds:\", y_pred[:10])\n",
    "\n",
    "    # GFQK baseline for comparison (optional; O(N^2) states)\n",
    "    gf_kernel = GFQK(gamma=0.5)\n",
    "    gf_clf = QuantumKernelSVC(kernel=gf_kernel, C=2.0).fit(X_train, y_train)\n",
    "    y_pred_gf = gf_clf.predict(X_test)\n",
    "    print(\"GFQK preds:\", y_pred_gf[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit14-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
